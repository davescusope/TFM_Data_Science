# TFM_Data_Science
## Data Science Master Final Project : Competition Margin Forecasting in Regulated Electricity Markets

### 1. Summary
The nature of this project is double:

On one hand, the objective of this TFM is to simulate a real jobcase for a data scientist.
Instead of starting from a predefined point within all the data is already gathered and prepared, we are gonna search , explore and flow through the transformatios needed to reach that very far point which which is being ready to train a machine learning model.

On the other hand, due to my daily job I am on a possition of priviledge to compare all the tools learnt on this masters degree  with 
the ones I'm more used to in my job ( SQL, SAS ). 





For this second point, and even when most of the data used in this project are available to be downloaded directly from the REE oficial webpage  "https://www.ree.es/es/estadisticas-del-sistema-electrico-espanol", I've prefered to use internal infomation after having been anonymized. This way I will be able to compare exactly how it is working with (R & Python) vs (SQL & SAS)


### 2. Previous Considerations
Every path on this project is a relative path, so since the whole folder is downloaded all together, it can be executed no matter where.


```
As mentioned before, I've opted for using information from my company after being previously anonymized.
For this purpose, there were used different procedures depending on the data-origin.

-For all those which came from an SQL data base, I used simple joins to replace all the data from the conflictive cells with the new ones. An example of the mulpliple SQL transformations can be watch on the links below

https://drive.google.com/open?id=10AUcEVijW7kJpaKWIv6xQTRc7dHBdTYb

https://drive.google.com/open?id=1acEfWbsbnwtrR_uR5v-J6XW0zwtYpJOj

-For all those which came fron an csv, xlsx file, the process was based on a simple searchv function and replace the whole column with the new one(this included SAP information since it was extracted through an excel platform called E4E)


```

### 3. Project Structure
This TFM has been structured following two different approaches:

The first one is the real data flow and how I have been developing it.

![Information flow](https://user-images.githubusercontent.com/46086706/58572480-0d0b3e00-823c-11e9-937b-83155000fd47.PNG)


THe second one is the general structure of this document, where you can see the main points of it.

**1. Summary**
  
**2. Previous Considerations**

**3. Project Structure**

**4. RProject TFM**
- 4.1 Market liquidations
- 4.2 Nuclear Wastes
- 4.3 SAP Costs


**5. Python Jupyter notebooks**

- 5.1 Import and preparation of data
- 5.2 Integrated Margin Design
- 5.3 Model design and feature engineering
- 5.4 Model aplication, train and fit

**6. Visualization from enriched data**

**7. Conclusions**



### 7. Conclusions

As said before, through the different phases of this project I could made an approach to the comparation between the different technologies I have used to build the integral margin of the company One.
Thanks to this situation, I will make the evaluation of the new ones vs the old ones based on 10 points.

Criteria are simple: 
- Every point has the same weight for the final mark ( eventhough we all know that not all of them are the same)
- I will evaluate them ONLY for the application on this project, and not for it's possibilities out of this frame



<center>

| ASPECT                      |      Python & R      |      SAS & SQL       |
|-----------------------------|:--------------------:|:--------------------:|
| Prize                       |         5            |           1          |
| Learning Rate               |         3            |           4          |
| Grouth & Industrialization  |         3            |           5          |
| Muscle to move information  |         3            |           5          |
| Query Ease                  |         3            |           5          |
| Groups and filters          |         3            |           5          |
| Data transformation         |         3            |           5          |
| Statistical Models          |         5            |           2          |
| Visualization               |         5            |           1          |
| Community & Support         |         5            |           3          |
|                             |                      |                      |
| **Total**                   |       38/50          |         36/50        |

</center>



## I will expose now the personal conclusions I got from this master from a whole point of view of the current data science situation out of the frame of this project:

- New techniques of analysis objectibly overcome the old ones as an average
- New techniques starts from a very disadvantageous point due to the fact that the old ones are already consolidated
- New techniques are freeware. Point of inflexion from the previous model of private licenses and payments
- New techniques are open source, fact that expose them to an exponential growth
- State of the art is now condensed on the new techniques


